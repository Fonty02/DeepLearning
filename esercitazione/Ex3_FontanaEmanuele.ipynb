{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3df8267",
   "metadata": {},
   "source": [
    "# Deep Learning - Exercise 3\n",
    "## Emanuele Fontana\n",
    "\n",
    "In this notebook we'll try to reach 90% accuracy on CIFAR-10 with 2 approaches:\n",
    "1. Using a simple Convolutional Neural Network (CNN) built with PyTorch\n",
    "2. Using Transfer Learning with a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb14174",
   "metadata": {},
   "source": [
    "### Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031c853a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchmetrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1775241068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Define transformations for CNN training (32x32)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# Define transformations for effnet18 training (224x224 with ImageNet normalization)\n",
    "transform_effnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ridimensiona a 224x224 per effnet18\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),  # ImageNet normalization (mean)\n",
    "                         (0.229, 0.224, 0.225))   # ImageNet normalization (std)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Custom dataset with multiple augmented versions\n",
    "class AugmentedCIFAR10(torchvision.datasets.CIFAR10):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_augmentations = 2\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) * self.num_augmentations\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the original image and label\n",
    "        original_idx = idx // self.num_augmentations\n",
    "        image_array = self.data[original_idx]\n",
    "        label = self.targets[original_idx]\n",
    "        \n",
    "        # Convert numpy array to PIL Image\n",
    "        image = Image.fromarray(image_array)\n",
    "        \n",
    "        if idx % self.num_augmentations == 0:\n",
    "            #original image\n",
    "            newImage = transforms.ToTensor()(image)\n",
    "            newImage = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(newImage)\n",
    "        else:\n",
    "            newImage = self.transform(image)\n",
    "\n",
    "        \n",
    "        return newImage, label\n",
    "\n",
    "# Load dataset with augmentation for CNN\n",
    "trainset = AugmentedCIFAR10(root='./data', train=True,\n",
    "                            download=True, transform=transform) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=300,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=300,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "# Load dataset with augmentation for effnet18\n",
    "trainset_effnet = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                   download=True, transform=transform_effnet) \n",
    "trainloader_effnet = torch.utils.data.DataLoader(trainset_effnet, batch_size=64,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "testset_effnet = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_effnet)\n",
    "testloader_effnet = torch.utils.data.DataLoader(testset_effnet, batch_size=64,\n",
    "                                                shuffle=False)\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b5331",
   "metadata": {},
   "source": [
    "### 1 - Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da39f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.gel1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.25)\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # Block 2\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.gel2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.25)\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # Block 3\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.gel3 = nn.GELU()\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.dropout3 = nn.Dropout2d(p=0.25)\n",
    "        self.skip3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # Block 4\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.gel4 = nn.GELU()\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.dropout4 = nn.Dropout2d(p=0.25)\n",
    "        self.skip4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # MLP head for classification\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fcre1lu = nn.ReLU()\n",
    "        self.bc1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fcre2lu = nn.ReLU()\n",
    "        self.bc2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First convolutional block with skip connection\n",
    "        identity = self.skip1(x)\n",
    "        x = self.dropout1(self.bn1(self.gel1(self.conv1(x))))\n",
    "        x = x + identity\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Second convolutional block with skip connection\n",
    "        identity = self.skip2(x)\n",
    "        x = self.dropout2(self.bn2(self.gel2(self.conv2(x))))\n",
    "        x = x + identity\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Third convolutional block with skip connection\n",
    "        identity = self.skip3(x)\n",
    "        x = self.dropout3(self.bn3(self.gel3(self.conv3(x))))\n",
    "        x = x + identity\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Fourth convolutional block with skip connection\n",
    "        identity = self.skip4(x)\n",
    "        x = self.dropout4(self.bn4(self.gel4(self.conv4(x))))\n",
    "        x = x + identity\n",
    "        \n",
    "        # Global pooling to keep the linear head lightweight\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.bc1(self.fcre1lu(self.fc1(x)))\n",
    "        x = self.bc2(self.fcre2lu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "022d03b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m loss.backward()\n\u001b[32m     37\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Update training metrics\u001b[39;00m\n\u001b[32m     41\u001b[39m metrics[\u001b[33m\"\u001b[39m\u001b[33mtrain_acc\u001b[39m\u001b[33m\"\u001b[39m].update(outputs, labels)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "epochs = 30\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "# Define torchmetrics objects\n",
    "metrics = {\n",
    "    \"train_acc\": Accuracy(task=\"multiclass\", num_classes=10).to(device),\n",
    "    \"test_acc\": Accuracy(task=\"multiclass\", num_classes=10).to(device),\n",
    "}\n",
    "\n",
    "patience = 10\n",
    "not_improved_epochs = 0\n",
    "best_test_acc = 0.0\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Reset train metrics each epoch\n",
    "    metrics[\"train_acc\"].reset()\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update training metrics\n",
    "        metrics[\"train_acc\"].update(outputs, labels)\n",
    "\n",
    "    # Compute train metrics\n",
    "    train_acc = metrics[\"train_acc\"].compute().item()\n",
    "\n",
    "    # Reset test metrics\n",
    "    metrics[\"test_acc\"].reset()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            metrics[\"test_acc\"].update(outputs, labels)\n",
    "\n",
    "    # Compute test metrics\n",
    "    test_acc = metrics[\"test_acc\"].compute().item()\n",
    "\n",
    "    # Early stopping logic\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        not_improved_epochs = 0\n",
    "    else:\n",
    "        not_improved_epochs += 1\n",
    "\n",
    "    if not_improved_epochs >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Log results\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(trainloader):.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67659ed",
   "metadata": {},
   "source": [
    "### 2 - Transfer Learning with Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f58d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10\n",
    "# Load pre-trained EfficientNet-B0\n",
    "effnet = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "# Replace the final classification layer for 10 classes\n",
    "effnet.classifier[1] = nn.Linear(effnet.classifier[1].in_features, num_classes)\n",
    "effnet = effnet.to(device)\n",
    "\n",
    "# Define optimizer and loss function for effnet\n",
    "criterion_effnet = nn.CrossEntropyLoss()\n",
    "optimizer_effnet = optim.AdamW(effnet.parameters(), lr=0.1)\n",
    "\n",
    "# Start fine-tuning effnet model by learning only the classification head\n",
    "# Freeze all backbone parameters\n",
    "for param in effnet.parameters():\n",
    "    param.requires_grad = False\n",
    "# Unfreeze only the classifier head\n",
    "for param in effnet.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "epochs_effnet = 30\n",
    "patience_effnet = 5\n",
    "not_improved_epochs_effnet = 0\n",
    "best_test_acc_effnet = 0.0\n",
    "\n",
    "\n",
    "for epoch in range(epochs_effnet):\n",
    "    effnet.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Reset train metrics each epoch\n",
    "    metrics[\"train_acc\"].reset()\n",
    "\n",
    "    for images, labels in trainloader_effnet:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer_effnet.zero_grad()\n",
    "        outputs = effnet(images)\n",
    "        loss = criterion_effnet(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_effnet.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update training metrics\n",
    "        metrics[\"train_acc\"].update(outputs, labels)\n",
    "\n",
    "    # Compute train metrics\n",
    "    train_acc = metrics[\"train_acc\"].compute().item()\n",
    "\n",
    "    # Reset test metrics\n",
    "    metrics[\"test_acc\"].reset()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    effnet.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader_effnet:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = effnet(images)\n",
    "            metrics[\"test_acc\"].update(outputs, labels)\n",
    "\n",
    "    # Compute test metrics\n",
    "    test_acc = metrics[\"test_acc\"].compute().item()\n",
    "\n",
    "    # Early stopping logic\n",
    "    if test_acc > best_test_acc_effnet:\n",
    "        best_test_acc_effnet = test_acc\n",
    "        not_improved_epochs_effnet = 0\n",
    "    else:\n",
    "        not_improved_epochs_effnet += 1\n",
    "    \n",
    "    if not_improved_epochs_effnet >= patience_effnet:\n",
    "        print(\"Early stopping triggered for EfficientNet-B0\")\n",
    "        break\n",
    "\n",
    "    # Log results\n",
    "    print(f\"EfficientNet-B0 Epoch [{epoch+1}/{epochs_effnet}] | Loss: {running_loss/len(trainloader_effnet):.4f} | \"\n",
    "            f\"Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
